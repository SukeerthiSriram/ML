
# BERT ONLY
# Since we already have the features saved, we only need to load the features and not run the above code.
# Function to load features
def load_features(file_name):
    load_path = os.path.join(save_dir, file_name)
    features = torch.load(load_path)
    print(f"Features loaded from {load_path}")
    return features

# Load the pre-extracted DistilBERT features
X_train_distilbert = load_features('X_train_distilbert.pt')
X_test_distilbert = load_features('X_test_distilbert.pt')

# Move features to CPU for sklearn
X_train_distilbert = X_train_distilbert.cpu()
X_test_distilbert = X_test_distilbert.cpu()

# Train logistic regression model using only DistilBERT features
clf = LogisticRegression(max_iter=1000)
print("Training Logistic Regression Model using DistilBERT features Only...")
clf.fit(X_train_distilbert.numpy(), y_train)

# Make predictions and evaluate
y_pred = clf.predict(X_test_distilbert.numpy())
print(classification_report(y_test, y_pred))

# Compute confusion matrix for binary classification (benign vs malware)
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix (benign=0, malware=1):\n", conf_matrix)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['benign', 'malware'], yticklabels=['benign', 'malware'])
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix (Binary Classification - DistilBERT Only)')
plt.show()

# Calculate and print individual metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
